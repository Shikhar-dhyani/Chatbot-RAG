{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import  SimpleDirectoryReader, ServiceContext\n",
    "# from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Import necessary libraries for document processing, vector embeddings, and interaction with Pinecone\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "# import numpy as np\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "# from langchain.prompts import PromptTemplate \n",
    "from pinecone import Pinecone, PodSpec\n",
    "from langchain_core.documents.base import Document\n",
    "# from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDFs loaded: 4\n",
      "Total pages loaded: 43\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "pdf_directory='Policies/'\n",
    "files = os.listdir(pdf_directory)\n",
    "\n",
    "# Filter for PDF files\n",
    "pdf_files = [file for file in files if file.endswith('.pdf')]\n",
    "\n",
    "# Initialize an empty list to hold all pages from all PDFs\n",
    "all_pages = []\n",
    "\n",
    "# Load and split each PDF\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(pdf_directory, pdf_file)\n",
    "    pdf_loader = PyPDFLoader(pdf_path)\n",
    "    pages = pdf_loader.load_and_split()\n",
    "    all_pages.extend(pages)  # Add the pages from the current PDF to the list of all pages\n",
    "\n",
    "# Now `all_pages` contains pages from all PDFs in the directory\n",
    "print(f'Total PDFs loaded: {len(pdf_files)}')\n",
    "print(f'Total pages loaded: {len(all_pages)}')\n",
    "print(type(all_pages[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine page contents into a single context string for processing\n",
    "context = \"\\n\".join(str(p.page_content) for p in all_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the combined context into manageable chunks for embedding generation\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3200, chunk_overlap=400)\n",
    "texts = text_splitter.split_text(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def generate_embeddings(texts):\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    \"\"\"\n",
    "    Generate embeddings for a list of texts using the SentenceTransformer model.\n",
    "    \n",
    "    Parameters:\n",
    "    texts (list of str): A list of sentences for which to generate embeddings.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: A NumPy array of shape (n_texts, embedding_size) containing the sentence embeddings.\n",
    "    \"\"\"\n",
    "    # The encode method directly returns the embeddings as a NumPy array\n",
    "    embeddings = model.encode(texts)\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_client = Pinecone(api_key=PINECONE_API_KEY)\n",
    "pinecone_index = pinecone_client.Index(\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map document IDs to texts and upsert embeddings into Pinecone\n",
    "id_to_text = {}  # Dictionary to map IDs to texts\n",
    "for i, text in enumerate(texts):\n",
    "    embedding_list = generate_embeddings([text])[0].tolist()\n",
    "    document_id = str(i)\n",
    "    pinecone_index.upsert(vectors=[(document_id, embedding_list)])\n",
    "    id_to_text[document_id] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text=\"how many leaves can employee can avail ?\"\n",
    "query_embedding = generate_embeddings([query_text])[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "query_results = pinecone_index.query(vector=query_embedding, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(\n",
    "        page_content=id_to_text.get(match['id'], \"Content not found\"),\n",
    "        metadata={\"score\": match['score'], \"page\": match['id']}\n",
    "    )\n",
    "    for match in query_results[\"matches\"]\n",
    "    if match['id'] in id_to_text  # Ensure the ID exists in id_to_text\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine page contents into a single context string for processing\n",
    "context = \"\\n\".join(str(p.page_content) for p in documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='• Total  31 Leaves  Annually  \\n \\n \\n21 PL \\nKind  of Leave  \\n5 SL \\n 5 CL\\n5  \\n  \\nCasual  Leaves - 5 in a Year  \\n \\n \\nCL leave  may  be used  : \\n• For personal  work/family  engagements  \\n• CL is not carried  forward  for the next  Leave  Year \\n• CL is not en-cashable  \\n• CL can be taken  for a minimum  period  of half day to a maximum  of 1.5 days  in a month.\\n6  \\n  \\n \\nSick Leaves  – 5 in a year  \\n \\nSL leave  may  be used  and intimated :  \\n• For medical  issues  \\n• If any employee  avails  more  than  3 sick leaves,  in continuity  he/she  needs  to present  Medical  \\ncertificate  by an Authorized  Doctor.  \\n• SL is not carried  forward  for the next  Leave  Year \\n• SL is not en -cashable\\n7  \\n  \\nPrivileged  Leaves  – 21 in a year  \\n \\n• Employees  can earn  21 PL in a year  w.e.f.  Date  of Joining  \\n• The entitlement  is accrued  at the rate of 1.75  days  per completed  month  of service.  \\n• The approval  and scheduling  of such  time  off will be subject  to prior Reporting  Manager  Approval  \\nand business  needs.  \\n• Employee  is required  to apply  for continuous  PLs at-least  5 days  in advance  \\n• Any un-utilized  PL by the end of year  will be carried  forwarded  to the next  year. \\n• The maximum  limit at any  time for  the PL is 30. \\n• PL are en-cashable\\n8  \\n Maternity  Leaves  \\n• Female  Employees  are entitled  to maternity  leave  for childbirth  and post -natal  care. \\n• This is in accordance  with  the provisions  of the Maternity Benefit  Act (1961) and  amendment of  the Maternity  Benefit  Act (2017).  \\n• Maternity  Leave  is applicable to  all female  Indian  team  members  who  have  completed  not less than  80 days  of actual work  of employment in  \\nthe twelve months immediately preceding  the date  of expected  delivery.  \\n• Maternity  Leave  can also be availed  during  probation  period  subject to  fulfilment  of above  clause.  \\n• Female Employee should not be pregnant at the time of joining the services, giving maternity benefits in such cases depends on the decision  \\nof the organization.  \\n• Female Employee is entitled to 26 weeks paid maternity leave. Maternity leave can be availed for a period of extending up to a maximum of 8  \\nweeks before the expected delivery date and approximately 18 weeks after the childbirth. However, it completely depends on the choice of  \\nthe woman  and circumstances.  \\n• Maternity  leave  can be used  a maximum  of two (2) occasions  during  an employee’s  tenure with  the Company.  All intervening  holidays  and \\nweekends falling during this period  of maternity leave are counted.  \\n• In order to avail Maternity Benefit, eligible employees are required to submit an application to their Reporting Manager  & HR along with  \\nsupporting  medical  documents.  This wou ld be to inform  the expected date  of delivery  and the date on  which  Maternity  Leave  is to commence.  \\n• If, because  of any complication,  leave  has to be extended(  Maximum  /upto  1 Month),  it can be done  but will fall under  LOP .Full discretion  \\nshall  rest with  the Management  for any extension  of maternity  leaves  .' metadata={'score': 0.510664225, 'page': '11'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: You are Chatbot you have to give precise and accurate results .Given the context: • Total  31 Leaves  Annually  \n",
      " \n",
      " \n",
      "21 PL \n",
      "Kind  of Leave  \n",
      "5 SL \n",
      " 5 CL\n",
      "5  \n",
      "  \n",
      "Casual  Leaves - 5 in a Year  \n",
      " \n",
      " \n",
      "CL leave  may  be used  : \n",
      "• For personal  work/family  engagements  \n",
      "• CL is not carried  forward  for the next  Leave  Year \n",
      "• CL is not en-cashable  \n",
      "• CL can be taken  for a minimum  period  of half day to a maximum  of 1.5 days  in a month.\n",
      "6  \n",
      "  \n",
      " \n",
      "Sick Leaves  – 5 in a year  \n",
      " \n",
      "SL leave  may  be used  and intimated :  \n",
      "• To cover    medical   leave (medical emer\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "# Load your model and tokenizer\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # Update this to your actual model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "\n",
    "query=\"how many leaves can employee can avail ?\"\n",
    "\n",
    "\n",
    "context = \" \".join([doc.page_content for doc in documents])\n",
    "\n",
    "enhanced_query = f\"You are Chatbot you have to give precise and accurate results .Given the context: {context}, respond with most accurate result and Most relevent result of : {query}\"\n",
    "\n",
    "    # Encode the enhanced query\n",
    "input_ids = tokenizer.encode(enhanced_query, return_tensors=\"pt\", truncation=True, max_length=200)\n",
    "\n",
    "    # Generate a response\n",
    "output_ids = model.generate(input_ids, max_length=210, num_return_sequences=1, temperature=1, do_sample=True)\n",
    "\n",
    "    # Decode the output to text\n",
    "response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: • Total  31 Leaves  Annually  \n",
      " \n",
      " \n",
      "21 PL \n",
      "Kind  of Leave  \n",
      "5 SL \n",
      " 5 CL\n",
      "5  \n",
      "  \n",
      "Casual  Leaves - 5 in a Year  \n",
      " \n",
      " \n",
      "CL leave  may  be used  : \n",
      "• For personal  work/family  engagements  \n",
      "• CL is not carried  forward  for the next  Leave  Year \n",
      "• CL is not en-cashable  \n",
      "• CL can be taken  for a minimum  period  of half day to a maximum  of 1.5 days  in a month.\n",
      "6  \n",
      "  \n",
      " \n",
      "Sick Leaves  – 5 in a year  \n",
      " \n",
      "SL leave  may  be used  and intimated :  \n",
      "• For medical  issues  \n",
      "• If any employee  avails  more  than  3 sick leaves,  in continuity  he/she  needs  to present  Medical  \n",
      "certificate  by an Authorized  Doctor.  \n",
      "• SL is not carried  forward  for the next  Leave  Year \n",
      "• SL is not en -cashable\n",
      "7  \n",
      "  \n",
      " \n",
      "Total Sick\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load your model and tokenizer\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "context = \" \".join([doc.page_content for doc in documents])  # Assuming 'documents' is defined\n",
    "\n",
    "enhanced_query = f\"You are Chatbot you have to give precise and accurate results .Given the context: {context}, respond with the most accurate result . Most relevant result of: {query_text}\"\n",
    "\n",
    "# Encode the enhanced query\n",
    "input_ids = tokenizer.encode(context, return_tensors=\"pt\", truncation=True, max_length=260)\n",
    "\n",
    "# Generate a response with tuned hyperparameters\n",
    "output_ids = model.generate(\n",
    "    input_ids,\n",
    "    max_length=270,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,  # Adjust for diversity vs confidence\n",
    "    top_k=20,  # Top-k sampling\n",
    "    top_p=0.95,  # Nucleus sampling\n",
    "    repetition_penalty=1.2,  # Adjust repetition penalty\n",
    ")\n",
    "\n",
    "# Decode the output to text\n",
    "response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
